
\section{Introduction}
Interactions between multiple entities (or nodes) are common in real-world applications. For example, consumers' activities can be viewed as interactions between \textit{customers}, \textit{service items} and \textit{providers}. These (high-order) interactions are naturally represented by tensors and analyzed by tensor factorization, which learns a set of latent factors to represent each participant. With the factor representations, we can discover the hidden structures within the entities, \eg clusters and outliers, and extract useful features to make predictions (in downstream tasks). 

While many excellent methods for tensor factorization have been proposed~\citep{Tucker66,Harshman70parafac,Chu09ptucker,kang2012gigatensor,choi2014dfacto}, they mainly conduct a multilinear decomposition, and might  be inadequate to capture more complex, nonlinear relationships. More importantly, they severely underuse the valuable temporal information along with the data. Most methods either drop the time stamps of the interactions,  summarizing the events as a count tensor~\citep{chi2012tensors, HaPlKo15, Hu2015CountTensor}, or discretize the time stamps into crude steps (\eg weeks or months), ignoring the temporal dependencies  in the same step~\citep{xiong2010temporal, schein2015bayesian, Schein:2016:BPT:3045390.3045686}.  Recently, \citet{zhe2018stochastic} formulates event-tensors (where the tensor entries are sequences of interaction events) to preserve the accurate timestamps. They used Hawkes processes to estimate the fine-grained, triggering effects between the interactions. However, their approach overlooks \textit{inhibition}, another ubiquitous effect between the events, and can still miss important temporal patterns. In addition, to compromise on the computational cost, they use a small time window to restrict the range of dependent events, and cannot capture long-term temporal influences of the interactions. 

%our approach
To overcome these limitations, we propose a self-modulating nonparametric Bayesian factorization model for event tensors, which not only can capture static, nonlinear  relationships of the entities, but also is flexible enough to capture a variety of short-term and long-term, excitation and inhibition effects among the interaction events, encoding these complex temporal effects into the factor representations.  Specifically, we use the latent factors to construct a set of mutually-governed, general random point processes to sample the observed interaction events. We first use a latent Gaussian process (GP) to sample a function of the factor representations to determine the type of temporal effect between each pair of interactions. The strength of the effect is further modelled as a kernel (similarity) function of their factors. In this way, both the type  and strength of the effect are absorbed into the factors, from which we can discover the underlying temporal structures. We then couple with another latent GP to sample the base rate as a (nonlinear) function of the factors, in order to estimate and fuse complex yet  static relationships between the entities. We use a scaled softplus function to additively integrate all the positive and negative influences from previous interactions to construct the rate function. For efficient inference, we take advantage of the convexity and log concavity of the rate function, and use the sparse variational GP framework~\cite{hensman2013gaussian} and Jensen's inequality to derive a fully decomposed model evidence lower bound (ELBO). Based on the ELBO, we develop an efficient stochastic optimization algorithm. The complexity of our algorithm is only proportional to the size of the mini-batches, while it captures all the long-term dependencies among the interactions. 


%evaluation
For evaluation, we examined our method on four real-world datasets. Our model nearly always achieves better predictive performance than the existing methods using Poisson processes, time factors, and Hawkes processes to incorporate temporal information. The training curves show that our inference algorithm converges reasonably fast and is resistant to overfitting. Finally, by looking into the latent factors estimated by our approach, we found interesting/meaningful structures both within the entities and within the events. We also found interesting temporal influence patterns.   

